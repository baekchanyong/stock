import streamlit as st
import FinanceDataReader as fdr
import pandas as pd
import numpy as np
import os
import time
import requests
import re
import yfinance as yf
from datetime import datetime, timedelta

# --- ì„¤ì • ---
DB_FILE = "stock_analysis_v67.csv"

st.set_page_config(page_title="V67 ê°€ì¹˜íˆ¬ì ë¶„ì„ê¸° (ì ì •ì£¼ê°€ ë³µêµ¬)", page_icon="ğŸ’", layout="wide")

# --- [í•µì‹¬] ê°•ë ¥í•œ ìˆ«ì ë³€í™˜ í•¨ìˆ˜ ---
def to_float(val):
    """
    ì–´ë–¤ ì´ìƒí•œ ê°’ì´ ë“¤ì–´ì™€ë„ ê°•ì œë¡œ ì‹¤ìˆ˜í˜•(float)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if pd.isna(val) or val == '' or val == 'N/A': return 0.0
    try:
        # ë¬¸ìì—´ì¸ ê²½ìš° ì‰¼í‘œ, í¼ì„¼íŠ¸ ì œê±°
        if isinstance(val, str):
            clean_val = val.replace(',', '').replace('%', '').strip()
            if clean_val == '-' or clean_val == '': return 0.0
            return float(clean_val)
        # ì´ë¯¸ ìˆ«ìì¸ ê²½ìš°
        return float(val)
    except:
        return 0.0

# --- í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ ---
def get_bok_base_rate():
    url = "https://finance.naver.com/marketindex/"
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers, timeout=2)
        response.encoding = 'cp949'
        html = response.text
        match = re.search(r'í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬.*?([0-9]{1}\.[0-9]{2})', html, re.DOTALL)
        if match: return float(match.group(1))
        return 3.25 
    except: return 3.25

# --- ê³¼ê±° ê¸ˆë¦¬ ---
def get_historical_base_rate(date_str):
    return 3.50

# --- ë°ì´í„° ìˆ˜ì§‘ (íœ´ì¼ ë³´ì •) ---
def get_stock_listing_with_retry(market, date_str, max_retries=5):
    curr_date = datetime.strptime(date_str, "%Y-%m-%d")
    for _ in range(max_retries):
        d_str = curr_date.strftime("%Y-%m-%d")
        try:
            df = fdr.StockListing(market, d_str)
            if not df.empty:
                return df
        except: pass
        curr_date -= timedelta(days=1)
    return pd.DataFrame()

# --- [í•µì‹¬ ìˆ˜ì •] ë°ì´í„° í™•ë³´ ë° ì—­ì‚° ë¡œì§ ê°•í™” ---
def get_robust_metrics(code, row):
    """
    EPS, BPSê°€ ì—†ìœ¼ë©´ PER, PBRê³¼ ì£¼ê°€ë¥¼ ì´ìš©í•´ ê°•ì œë¡œ ì—­ì‚°í•©ë‹ˆë‹¤.
    """
    current_price = to_float(row.get('Close', 0))
    
    # 1. 1ì°¨ ì‹œë„: ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê°’ ê°€ì ¸ì˜¤ê¸°
    eps = to_float(row.get('EPS', 0))
    bps = to_float(row.get('BPS', 0))
    per = to_float(row.get('PER', 0))
    pbr = to_float(row.get('PBR', 0))
    
    # 2. 2ì°¨ ì‹œë„: ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ (0ì¼ ê²½ìš°ë§Œ)
    if eps == 0 or bps == 0:
        try:
            ticker = yf.Ticker(f"{code}.KS")
            info = ticker.info
            if eps == 0 and info.get('trailingEps'): eps = float(info['trailingEps'])
            if bps == 0 and info.get('bookValue'): bps = float(info['bookValue'])
        except: pass
        
    # 3. 3ì°¨ ì‹œë„: ì—­ì‚° (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
    # EPS = ì£¼ê°€ / PER
    if eps == 0 and current_price > 0 and per > 0:
        eps = current_price / per
        
    # BPS = ì£¼ê°€ / PBR
    if bps == 0 and current_price > 0 and pbr > 0:
        bps = current_price / pbr
        
    # 4. ìµœí›„ì˜ ë°©ì–´: PBRì€ ìˆëŠ”ë° BPSê°€ ì—†ìœ¼ë©´ ì—­ì‚°
    # ê·¸ë˜ë„ ì—†ìœ¼ë©´ 0 ë¦¬í„´ (ì ì ê¸°ì—… ë“±)
        
    return eps, bps

# --- ê³µí¬íƒìš•ì§€ìˆ˜ ---
def calculate_fear_greed_from_slice(df_slice):
    if len(df_slice) < 10: return 50
    delta = df_slice['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    
    ma20 = df_slice['Close'].rolling(window=20).mean()
    disparity = (df_slice['Close'] / ma20) * 100
    disparity_score = disparity.apply(lambda x: 0 if x < 90 else (100 if x > 110 else (x - 90) * 5))
    try:
        val = (rsi.iloc[-1] * 0.5) + (disparity_score.iloc[-1] * 0.5)
        return 50 if pd.isna(val) else val
    except: return 50

# --- CSV ì €ì¥ (í‰íƒ„í™”) ---
def save_to_csv_flat(data_list):
    if not data_list: return
    df = pd.DataFrame(data_list)
    new_cols = []
    for col in df.columns:
        if isinstance(col, tuple):
            new_cols.append(f"{col[0]}_{col[1]}")
        else:
            new_cols.append(str(col))
    df.columns = new_cols
    
    if not os.path.exists(DB_FILE):
        df.to_csv(DB_FILE, index=False, encoding='utf-8-sig')
    else:
        df.to_csv(DB_FILE, mode='a', header=False, index=False, encoding='utf-8-sig')

# --- ë¶„ì„ ì‹¤í–‰ ---
def run_history_analysis(target_stocks, applied_rate, status_text, progress_bar):
    today = datetime.now()
    quarters = []
    temp_date = today
    for _ in range(8):
        temp_date = temp_date - timedelta(days=95)
        q_date_str = temp_date.strftime('%Y-%m-%d')
        quarters.append(q_date_str)
    
    status_text.info(f"ğŸ“… ê³¼ê±° 2ë…„(8ê°œ ë¶„ê¸°) ë°ì´í„°ë¥¼ ë³µì› ì¤‘ì…ë‹ˆë‹¤...")

    # ê³¼ê±° ë°ì´í„° ìŠ¤ëƒ…ìƒ· ë¡œë”©
    snapshot_dfs = {}
    try:
        for i, q_date in enumerate(quarters):
            status_text.text(f"ğŸ“¥ [{i+1}/8] {q_date} ê¸°ì¤€ ë°ì´í„° í™•ë³´ ì¤‘...")
            df = get_stock_listing_with_retry('KRX', q_date)
            if not df.empty:
                snapshot_dfs[q_date] = df.set_index('Code')
    except Exception as e:
        st.error(f"ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        return

    if os.path.exists(DB_FILE): os.remove(DB_FILE)

    total = len(target_stocks)
    new_data = []
    
    chart_start = (today - timedelta(days=365*2.5)).strftime('%Y-%m-%d')
    today_str = today.strftime('%Y-%m-%d')

    for step, (idx, row) in enumerate(target_stocks.iterrows()):
        code = str(row['Code'])
        name = row['Name']
        
        if name in ["ë§¥ì¿¼ë¦¬ì¸í”„ë¼", "SKë¦¬ì¸ "]: continue
        
        progress_bar.progress(min((step + 1) / total, 1.0))
        status_text.text(f"â³ [{step+1}/{total}] {name} ë¶„ì„ ì¤‘...")
        
        try:
            current_price = to_float(row.get('Close', 0))
            
            # [ìˆ˜ì •] ê°•ë ¥í•´ì§„ ë°ì´í„° í™•ë³´ í•¨ìˆ˜ í˜¸ì¶œ
            eps_now, bps_now = get_robust_metrics(code, row)
            
            time.sleep(0.02)
            df_chart_full = fdr.DataReader(code, chart_start, today_str)
            
            fg_score_now = 50
            if not df_chart_full.empty:
                fg_score_now = calculate_fear_greed_from_slice(df_chart_full.tail(60))
            
            # ì ì •ì£¼ê°€ ê³„ì‚° (ì•ˆì „ì¥ì¹˜: ê¸ˆë¦¬ 0 ë°©ì§€)
            base_rate = applied_rate if applied_rate > 0 else 3.5
            
            # ìˆ˜ìµê°€ì¹˜ (EPS ê¸°ë°˜)
            earnings_val = eps_now / (base_rate/100)
            
            # ìì‚°ê°€ì¹˜ (BPS ê¸°ë°˜)
            asset_val = bps_now
            
            # 7:3 ê°€ì¤‘ì¹˜
            base_fair = (earnings_val * 0.7) + (asset_val * 0.3)
            
            # ì‹¬ë¦¬ ë³´ì •
            sentiment = 1 + ((50 - fg_score_now)/50 * 0.1)
            fair_now = base_fair * sentiment
            
            gap_now = 0
            if current_price > 0:
                gap_now = (fair_now - current_price) / current_price * 100
            
            # ROE ê³„ì‚° (ë³´ì—¬ì£¼ê¸°ìš©)
            roe_now = 0
            if bps_now > 0: roe_now = (eps_now / bps_now) * 100
            
            data_row = {
                'ê¸°ë³¸ì •ë³´_ì¢…ëª©ì½”ë“œ': code,
                'ê¸°ë³¸ì •ë³´_ì¢…ëª©ëª…': name,
                'í˜„ì¬ì •ë³´_í˜„ì¬ê°€': round(current_price, 0),
                'í˜„ì¬ì •ë³´_ì ì •ì£¼ê°€': round(fair_now, 0),
                'í˜„ì¬ì •ë³´_ê´´ë¦¬ìœ¨': round(gap_now, 2),
                'ì§€í‘œ_ê³µí¬ì§€ìˆ˜': round(fg_score_now, 1),
                'ì§€í‘œ_EPS': round(eps_now, 0),
                'ì§€í‘œ_BPS': round(bps_now, 0),
                'ì§€í‘œ_ROE(%)': round(roe_now, 2)
            }
            
            # ê³¼ê±° ë°ì´í„° (íˆìŠ¤í† ë¦¬) ì²˜ë¦¬
            for q_date in quarters:
                q_end_dt = datetime.strptime(q_date, '%Y-%m-%d')
                q_start_dt = q_end_dt - timedelta(days=90)
                q_start_str = q_start_dt.strftime('%Y-%m-%d')
                
                yyyy = q_end_dt.year
                mm = q_end_dt.month
                q_num = (mm - 1) // 3 + 1
                if q_num == 0: q_num = 4; yyyy -= 1
                col_group = f"{str(yyyy)[2:]}ë…„{q_num}Q"
                
                q_avg_price = 0
                q_fair = 0
                
                if not df_chart_full.empty:
                    q_chart = df_chart_full.loc[q_start_str:q_date]
                    if not q_chart.empty:
                        q_avg_price = q_chart['Close'].mean()
                        
                        # ìŠ¤ëƒ…ìƒ· ì°¾ê¸°
                        found_snap = None
                        for snap_date in snapshot_dfs.keys():
                            diff = abs((datetime.strptime(snap_date, '%Y-%m-%d') - q_end_dt).days)
                            if diff < 10:
                                found_snap = snapshot_dfs[snap_date]
                                break
                        
                        if found_snap is not None and code in found_snap.index:
                            snap_row = found_snap.loc[code]
                            
                            # [ì¤‘ìš”] ê³¼ê±° ë°ì´í„°ë„ ê°•ë ¥í•œ ì—­ì‚° ë¡œì§ ì ìš©
                            q_eps, q_bps = get_robust_metrics(code, snap_row)
                            
                            q_fg = calculate_fear_greed_from_slice(q_chart)
                            q_rate = get_historical_base_rate(q_date)
                            
                            # ì ì •ì£¼ê°€ ê³„ì‚°
                            q_rate = q_rate if q_rate > 0 else 3.5
                            q_earn = q_eps / (q_rate/100)
                            q_base = (q_earn * 0.7) + (q_bps * 0.3)
                            q_sent = 1 + ((50 - q_fg)/50 * 0.1)
                            q_fair = q_base * q_sent
                
                data_row[f"{col_group}_í‰ê· ì£¼ê°€"] = round(q_avg_price, 0)
                data_row[f"{col_group}_ì ì •ì£¼ê°€"] = round(q_fair, 0)

            new_data.append(data_row)
            
            if len(new_data) >= 5:
                save_to_csv_flat(new_data)
                new_data = []
        except: continue

    if new_data:
        save_to_csv_flat(new_data)
            
    progress_bar.empty()
    return True

# --- ë©”ì¸ UI ---

st.title("ğŸ’ V67 ê°€ì¹˜íˆ¬ì ë¶„ì„ê¸° (ì ì •ì£¼ê°€ ë³µêµ¬)")

with st.expander("ğŸ“˜ **[í•„ë…] ì ì •ì£¼ê°€ ì‚°ì¶œ ê³µì‹**", expanded=True):
    c1, c2 = st.columns(2)
    with c1:
        st.markdown("##### ğŸ§® ì ì •ì£¼ê°€ (ìˆ˜ìµ7 : ìì‚°3)")
        st.latex(r"\text{ì ì •ì£¼ê°€} = \left[ \left( \frac{\text{EPS}}{\text{ê¸ˆë¦¬}} \times 0.7 \right) + \left( \text{BPS} \times 0.3 \right) \right] \times \text{ì‹¬ë¦¬ë³´ì •}")
        st.caption("* ê¸ˆë¦¬: í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ (ì•½ 3.25%)")
    with c2:
        st.markdown("##### ğŸ‘» ê³µí¬íƒìš•ì§€ìˆ˜")
        st.latex(r"\text{Index} = (\text{RSI}_{14} \times 0.5) + (\text{ì´ê²©ë„}_{20} \text{ ì ìˆ˜} \times 0.5)")

st.divider()

# --- 1. ì„¤ì • ---
st.header("1. ë¶„ì„ ì„¤ì •")

mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["ğŸ† ì‹œê°€ì´ì•¡ ìƒìœ„", "ğŸ” ì¢…ëª© ê²€ìƒ‰"], horizontal=True)
target_stocks = pd.DataFrame()

if mode == "ğŸ† ì‹œê°€ì´ì•¡ ìƒìœ„":
    if 'stock_count' not in st.session_state:
        st.session_state.stock_count = 200

    def update_from_slider():
        st.session_state.stock_count = st.session_state.slider_key

    def apply_manual_input():
        st.session_state.stock_count = st.session_state.num_key

    c1, c2 = st.columns([3, 1])
    with c1:
        st.slider("ì¢…ëª© ìˆ˜", 10, 500, key='slider_key', value=st.session_state.stock_count, on_change=update_from_slider)
    with c2:
        st.number_input("ì§ì ‘ ì…ë ¥", 10, 500, key='num_key', value=st.session_state.stock_count)
        if st.button("âœ… ìˆ˜ì¹˜ ì ìš©", on_click=apply_manual_input):
            st.rerun()

elif mode == "ğŸ” ì¢…ëª© ê²€ìƒ‰":
    query = st.text_input("ì¢…ëª©ëª… ê²€ìƒ‰", placeholder="ì˜ˆ: ì‚¼ì„±")
    if query:
        try:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                df_krx = fdr.StockListing('KRX')
                res = df_krx[df_krx['Name'].str.contains(query, case=False)]
                if res.empty: st.error("ê²°ê³¼ ì—†ìŒ")
                else:
                    picks = st.multiselect("ì„ íƒ", res['Name'].tolist(), default=res['Name'].tolist()[:5])
                    target_stocks = res[res['Name'].isin(picks)]
        except: st.error("ì˜¤ë¥˜")

# --- 2. ì‹¤í–‰ ---
st.divider()
if st.button("â–¶ï¸ ë¶„ì„ ì‹œì‘ (Start)", type="primary", use_container_width=True):
    
    if mode == "ğŸ† ì‹œê°€ì´ì•¡ ìƒìœ„":
        with st.spinner("ë¦¬ìŠ¤íŠ¸ ë¡œë”©..."):
            df_krx = fdr.StockListing('KRX')
            df_krx = df_krx[df_krx['Market'].isin(['KOSPI'])]
            final_target = df_krx.sort_values(by='Marcap', ascending=False).head(st.session_state.stock_count)
    else:
        if target_stocks.empty:
            st.warning("ì¢…ëª©ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            st.stop()
        final_target = target_stocks

    status_box = st.empty()
    status_box.info("ğŸ‡°ğŸ‡· í•œêµ­ì€í–‰ ê¸°ì¤€ê¸ˆë¦¬ ì¡°íšŒ ì¤‘...")
    
    bok_rate = get_bok_base_rate()
    applied_rate = bok_rate if bok_rate else 3.25
    
    status_box.success(f"âœ… ê¸°ì¤€ê¸ˆë¦¬ **{applied_rate}%** ì ìš© | ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    time.sleep(0.5)
    
    p_bar = st.progress(0)
    run_history_analysis(final_target, applied_rate, status_box, p_bar)
    
    status_box.success(f"âœ… ë¶„ì„ ì™„ë£Œ!")

# --- 3. ê²°ê³¼ ---
st.divider()
st.header("ğŸ† íˆìŠ¤í† ë¦¬ì¹¼ ë¶„ì„ ê²°ê³¼")

sort_opt = st.radio("ì •ë ¬ ê¸°ì¤€", ["ê´´ë¦¬ìœ¨ ë†’ì€ ìˆœ", "ROE ë†’ì€ ìˆœ", "ê³µí¬ì§€ìˆ˜ ë‚®ì€ ìˆœ"], horizontal=True)

if st.button("ğŸ”„ ê²°ê³¼ ìƒˆë¡œê³ ì¹¨"): st.rerun()

if os.path.exists(DB_FILE):
    try:
        df = pd.read_csv(DB_FILE)
        
        numeric_targets = ['í˜„ì¬ê°€', 'ì ì •ì£¼ê°€', 'ê´´ë¦¬ìœ¨', 'EPS', 'BPS', 'ROE', 'ê³µí¬ì§€ìˆ˜', 'í‰ê· ì£¼ê°€', 'ì ì •ê°€']
        for col in df.columns:
            if any(t in col for t in numeric_targets):
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
        if 'ê¸°ë³¸ì •ë³´_ì¢…ëª©ì½”ë“œ' in df.columns:
            df = df.drop_duplicates(['ê¸°ë³¸ì •ë³´_ì¢…ëª©ì½”ë“œ'], keep='last')
        elif 'ì¢…ëª©ì½”ë“œ' in df.columns:
             df = df.drop_duplicates(['ì¢…ëª©ì½”ë“œ'], keep='last')
        
        # [ìˆ˜ì •] ì ì •ê°€ 0ì›ì¸ ì¢…ëª©ë„ í‘œì‹œ (ë°ì´í„° ìƒíƒœ í™•ì¸ìš©)
        # df = df[df['í˜„ì¬ì •ë³´_ì ì •ì£¼ê°€'] > 0] <--- ì œê±°í•¨
        
        # ì •ë ¬
        sort_col = 'í˜„ì¬ì •ë³´_ê´´ë¦¬ìœ¨'
        ascending = False
        if "ROE" in sort_opt: sort_col = 'ì§€í‘œ_ROE(%)'
        elif "ê³µí¬" in sort_opt: 
            sort_col = 'ì§€í‘œ_ê³µí¬ì§€ìˆ˜'
            ascending = True
        
        if sort_col in df.columns:
            df = df.sort_values(by=sort_col, ascending=ascending)
        
        df = df.reset_index(drop=True)
        df.index += 1
        df.index.name = "ìˆœìœ„"

        # UI ë³µì›
        if 'ê¸°ë³¸ì •ë³´_ì¢…ëª©ëª…' in df.columns:
            df_display = df.set_index('ê¸°ë³¸ì •ë³´_ì¢…ëª©ëª…', append=True)
        else:
            df_display = df

        new_cols = []
        for col in df_display.columns:
            if "_" in col:
                parts = col.split("_", 1)
                new_cols.append((parts[0], parts[1]))
            else:
                new_cols.append(("ê¸°íƒ€", col))
        
        df_display.columns = pd.MultiIndex.from_tuples(new_cols)
        
        # ì»¬ëŸ¼ ìˆœì„œ
        display_cols = [
            ('í˜„ì¬ì •ë³´', 'í˜„ì¬ê°€'), ('í˜„ì¬ì •ë³´', 'ì ì •ì£¼ê°€'), ('í˜„ì¬ì •ë³´', 'ê´´ë¦¬ìœ¨'),
            ('ì§€í‘œ', 'ê³µí¬ì§€ìˆ˜'), ('ì§€í‘œ', 'ROE(%)'), ('ì§€í‘œ', 'EPS'), ('ì§€í‘œ', 'BPS')
        ]
        
        levels = df_display.columns.levels[0]
        hist_groups = [l for l in levels if 'ë…„' in l and 'Q' in l]
        hist_groups.sort(reverse=True)
        
        for q in hist_groups:
            display_cols.append((q, 'í‰ê· ì£¼ê°€'))
            display_cols.append((q, 'ì ì •ì£¼ê°€'))
            
        final_cols = [c for c in display_cols if c in df_display.columns]
        
        if not df_display.empty:
            try:
                top_row = df.iloc[0]
                t_name = top_row.name[1] if isinstance(top_row.name, tuple) else top_row.name
                t_gap = top_row.get(('í˜„ì¬ì •ë³´', 'ê´´ë¦¬ìœ¨'), 0)
                st.info(f"ğŸ¥‡ **1ìœ„: {t_name}** | í˜„ì¬ ê´´ë¦¬ìœ¨: {t_gap}%")
            except: pass

        st.dataframe(
            df_display[final_cols].style.applymap(
                lambda x: 'color: red; font-weight: bold;' if x > 20 else ('color: blue;' if x < 0 else 'color: black;'), 
                subset=[('í˜„ì¬ì •ë³´', 'ê´´ë¦¬ìœ¨')] if ('í˜„ì¬ì •ë³´', 'ê´´ë¦¬ìœ¨') in df_display.columns else []
            ).format("{:,.0f}", na_rep="-"),
            height=800,
            use_container_width=True
        )
        
    except Exception as e: st.error(f"í‘œì‹œ ì˜¤ë¥˜ ìƒì„¸: {e}")
else: st.info("ğŸ‘ˆ ìœ„ì—ì„œ [ë¶„ì„ ì‹œì‘] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
